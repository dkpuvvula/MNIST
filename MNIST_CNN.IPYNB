#CNN
import torch
import torch.nn as nn
import torchvision
import torchvision.datasets as datasets
from torch.utils.data import DataLoader
import torchvision.transforms as transform
import matplotlib.pyplot as plt
from torch.autograd import Variable
import torch.nn.functional as F

training_data = datasets.MNIST(
    root="data",
    train=True,
    download=True,
    transform=transform.ToTensor()
)

test_data = datasets.MNIST(
    root="data",
    train=False,
    download=True,
    transform=transform.ToTensor()
)
train_dataloader = DataLoader(training_data, batch_size=100, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size=100, shuffle=True)
examples = iter(test_dataloader)
example_data, example_targets = examples.next()

for i in range(10):
    plt.subplot(2,5,i+1)
    plt.imshow(example_data[i][0], cmap='gray')
plt.show()
class CNN(nn.Module):

  def __init__(self):

    super(CNN,self) .__init__()
    self.cnn1 = nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5,stride=1,padding=0) #64,1,28,28
    self.relu1 = torch.nn.ReLU()                                                          #28-5+1 =24 (64,16,24,24)
    self.pool1 = nn.MaxPool2d(kernel_size=2)                                              # 64,16,12,12

    self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size= 5)                #64,16,12,12            
    self.relu2 = torch.nn.ReLU()                                                          #12-5+1 = 8 (64,32,8,8)
    self.pool2 = nn.MaxPool2d(kernel_size=2)                                              #64,32,4,4

    self.fc1 = nn.Linear(in_features=512,out_features=100)
    self.fc2 = nn.Linear(in_features=100, out_features=84)
    self.fc3 = nn.Linear(in_features=84, out_features=10)

  def forward(self,x):
    #64,1,28,28
    out = self.cnn1(x)
    #print(out.shape)
    out = self.relu1(out)
    out = self.pool1(out)
    #print(out.shape)

    out = self.cnn2(out)
    #print(out.shape)
    out = self.relu2(out)
    out = self.pool2(out)
    #print(out.shape)

    out = out.view(x.shape[0],-1)
    #print(out.shape)
    out = self.fc1(out)
    out = self.fc2(out)        
    out = self.fc3(out)   
    #print(out.shape)                    
    return out
model=CNN()
error = nn.CrossEntropyLoss()
learning_rate = 0.01
num_epochs=10

optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)
for epochs in range(num_epochs):
  for i, (images, labels) in enumerate(train_dataloader):
    #images = images.reshape(-1, 28*28)
   
    optimizer.zero_grad()
    outputs = model(images)
    loss= error(outputs,labels)
    loss.backward()
    optimizer.step()
   #if (i+1)%100 ==0:
    #print (f'Epoch [{epochs+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')
# test data
with torch.no_grad():
    n_correct = 0
    n_samples = 0
    for images, labels in test_dataloader:
        #images = Variable(images.view(images.size(0), -1))
        #images = images.reshape(images.view(images.size(0), -1))
        outputs = model(images)
        # max returns (value ,index)
        _, predicted = torch.max(outputs.data, 1)
        n_samples += labels.size(0)
        n_correct += (predicted == labels).sum().item()

    acc = 100.0 * n_correct / n_samples
    print(f'Accuracy of the network on the 10000 test images: {acc} %')
